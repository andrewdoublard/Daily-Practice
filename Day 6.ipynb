{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8712c9",
   "metadata": {},
   "source": [
    "#### Data Understanding and Exploration\n",
    "- Dataset: Load the Wine Quality dataset (available on UCI Machine Learning Repository or other sources).\n",
    "- Explore the Data:\n",
    "    - Load the dataset and convert it into a Pandas DataFrame.\n",
    "    - Examine the first few rows, check for missing values, and get a summary of the dataset.\n",
    "\n",
    "- Questions:\n",
    "    - What are the input features and target variables?\n",
    "    - Are there any missing values or outliers that might need attention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b72e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from ucimlrepo) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from ucimlrepo) (2022.9.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22995c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  targets  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n",
      "fixed_acidity           0\n",
      "volatile_acidity        0\n",
      "citric_acid             0\n",
      "residual_sugar          0\n",
      "chlorides               0\n",
      "free_sulfur_dioxide     0\n",
      "total_sulfur_dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "targets                 0\n",
      "dtype: int64\n",
      "       fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
      "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
      "mean        7.215307          0.339666     0.318633        5.443235   \n",
      "std         1.296434          0.164636     0.145318        4.757804   \n",
      "min         3.800000          0.080000     0.000000        0.600000   \n",
      "25%         6.400000          0.230000     0.250000        1.800000   \n",
      "50%         7.000000          0.290000     0.310000        3.000000   \n",
      "75%         7.700000          0.400000     0.390000        8.100000   \n",
      "max        15.900000          1.580000     1.660000       65.800000   \n",
      "\n",
      "         chlorides  free_sulfur_dioxide  total_sulfur_dioxide      density  \\\n",
      "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
      "mean      0.056034            30.525319            115.744574     0.994697   \n",
      "std       0.035034            17.749400             56.521855     0.002999   \n",
      "min       0.009000             1.000000              6.000000     0.987110   \n",
      "25%       0.038000            17.000000             77.000000     0.992340   \n",
      "50%       0.047000            29.000000            118.000000     0.994890   \n",
      "75%       0.065000            41.000000            156.000000     0.996990   \n",
      "max       0.611000           289.000000            440.000000     1.038980   \n",
      "\n",
      "                pH    sulphates      alcohol      targets  \n",
      "count  6497.000000  6497.000000  6497.000000  6497.000000  \n",
      "mean      3.218501     0.531268    10.491801     5.818378  \n",
      "std       0.160787     0.148806     1.192712     0.873255  \n",
      "min       2.720000     0.220000     8.000000     3.000000  \n",
      "25%       3.110000     0.430000     9.500000     5.000000  \n",
      "50%       3.210000     0.510000    10.300000     6.000000  \n",
      "75%       3.320000     0.600000    11.300000     6.000000  \n",
      "max       4.010000     2.000000    14.900000     9.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16760\\3959803869.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['targets'] = wine_quality.data.targets\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) \n",
    "  \n",
    "df = wine_quality.data.features \n",
    "df['targets'] = wine_quality.data.targets \n",
    "\n",
    "print(df.head()) ## Examinin first few rows.\n",
    "print(df.isnull().sum()) ## Checking for missing values.\n",
    "print(df.describe()) ## Summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04690f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datasets features are: Index(['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
      "       'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol'],\n",
      "      dtype='object')\n",
      "The datasets targets are: Index(['quality'], dtype='object')\n",
      "There are no missing values that might need attention\n",
      "There are two features (Residual Suger, Free Sulphor Dioxide) which have a max value of roughly 13x, and 9x their mean respectively. Therefore these may be outliers. The question didnt specify to explore the data further so I will not, but in the case that I had to i would use a box plot on these two features to see if they have outliers.\n"
     ]
    }
   ],
   "source": [
    "features = wine_quality.data.features \n",
    "targets = wine_quality.data.targets \n",
    "\n",
    "print(f'The datasets features are: {features.columns[0:-1]}') \n",
    "print(f'The datasets targets are: {targets.columns}')\n",
    "\n",
    "print(f'There are no missing values that might need attention')\n",
    "print(f'There are two features (Residual Suger, Free Sulphor Dioxide) which have a max value of roughly 13x, and 9x their mean respectively. Therefore these may be outliers. The question didn''t specify to explore the data further so I will not, but in the case that I had to i would use a box plot on these two features to see if they have outliers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ea0bd",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "- Preprocess the Data:\n",
    "    - Split the dataset into features (X) and target (y).\n",
    "    - Perform an 80-20 split for training and testing.\n",
    "- Scale the features using StandardScaler or another appropriate method.\n",
    "\n",
    "- Questions:\n",
    "    - Why is it necessary to split your data into training and testing sets?\n",
    "    - Why is scaling features important before applying regularized models such as Ridge or Lasso?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50808cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (5197, 11)\n",
      "Shape of test set: (1300, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_unscaled = df.drop(columns = 'targets')\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_unscaled)\n",
    "y = df['targets']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "print(f'Shape of train set: {X_train.shape}')\n",
    "print(f'Shape of test set: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3808d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its necessary to split data so you can test your model on data which is hasnt seen. In essence, reflecting a real life scenario where the variables are known but the output is yet to be. Hence, performance on the test set will give an indicator to the models success when deployed.\n",
      "Scaling is important for Ridge and Lasso so that going into the model, each feature will have an equal weighting or influence on the models output before the Ridge or Lasso model chooses to downweight the less influential features. In short, the features go in equal so they can be compared fairly and accurately, without any artificial up or down weighting adversely effecting the model performance.\n"
     ]
    }
   ],
   "source": [
    "print(f'It''s necessary to split data so you can test your model on data which is hasn''t seen. In essence, reflecting a real life scenario where the variables are known but the output is yet to be. Hence, performance on the test set will give an indicator to the models success when deployed.')\n",
    "print(f'Scaling is important for Ridge and Lasso so that going into the model, each feature will have an equal weighting or influence on the models output before the Ridge or Lasso model chooses to downweight the less influential features. In short, the features go in equal so they can be compared fairly and accurately, without any artificial up or down weighting adversely effecting the model performance.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8773d7",
   "metadata": {},
   "source": [
    "#### Modeling and Evaluation\n",
    "- Train and Compare Models:\n",
    "    - Train Ridge Regression, Lasso Regression, and Linear Regression models using the training set.\n",
    "    - Evaluate the models using the Mean Squared Error (MSE) and R² score on the test set.\n",
    "- Questions:\n",
    "    - How do the models perform compared to each other?\n",
    "    - What insights can you derive about the differences between Ridge, Lasso, and Linear Regression from the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d6196a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   linear_msq  ridge_msq  lasso_msq\n",
      "0     0.54187   0.541873   0.783099\n",
      "   linear_r2  ridge_r2  lasso_r2\n",
      "0   0.307616  0.307613 -0.000619\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "linear = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "linear.fit(X_train, y_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "linear_pred = linear.predict(X_test)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "linear_msq = mean_squared_error(y_test, linear_pred)\n",
    "ridge_msq = mean_squared_error(y_test, ridge_pred)\n",
    "lasso_msq = mean_squared_error(y_test, lasso_pred)\n",
    "\n",
    "linear_r2 = r2_score(y_test, linear_pred)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)\n",
    "\n",
    "msq_performance = pd.DataFrame({\n",
    "    'linear_msq': [linear_msq],\n",
    "    'ridge_msq': [ridge_msq],\n",
    "    'lasso_msq': [lasso_msq]\n",
    "})\n",
    "\n",
    "r2_performance = pd.DataFrame({\n",
    "    'linear_r2': [linear_r2],\n",
    "    'ridge_r2': [ridge_r2],\n",
    "    'lasso_r2': [lasso_r2]\n",
    "})\n",
    "\n",
    "print(msq_performance)\n",
    "print(r2_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0834b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear and Ridge models perform equally unsatisfactory, both accounting for only 30% of the variance via the r2 score. However, the Lasso model performed the worse with almost none of the variance explained, which indicates its over penalising during the feature selection process.\n"
     ]
    }
   ],
   "source": [
    "print(f'The Linear and Ridge models perform equally unsatisfactory, both accounting for only 30% of the variance via the r2 score. However, the Lasso model performed the worse with almost none of the variance explained, which indicates it''s over penalising during the feature selection process.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97e566",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "- Hyperparameter Tuning:\n",
    "    - Use GridSearchCV to find the best alpha for both Ridge and Lasso models. Use a range of alpha values (e.g., [0.001, 0.01, 0.1, 1, 10]).\n",
    "- Evaluate the tuned models' performance.\n",
    "\n",
    "- Questions:\n",
    "    - What are the optimal alpha values for Ridge and Lasso, and how did they affect the model performance?\n",
    "    - Did tuning the hyperparameters improve the models significantly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "049b8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ridge_grid_msq  lasso_grid_msq\n",
      "0        0.541892        0.542073\n",
      "   ridge_grid_r2  lasso_grid_r2\n",
      "0       0.307587       0.307357\n",
      "Optimal Alpha for Ridge Model: {'alpha': 10}\n",
      "Optimal Alpha for Lasso Model: {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "ridge_grid = GridSearchCV(ridge, params)\n",
    "lasso_grid = GridSearchCV(lasso, params)\n",
    "\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "ridge_grid_pred = ridge_grid.predict(X_test)\n",
    "lasso_grid_pred = lasso_grid.predict(X_test)\n",
    "\n",
    "ridge_grid_msq = mean_squared_error(y_test, ridge_grid_pred)\n",
    "lasso_grid_msq = mean_squared_error(y_test, lasso_grid_pred)\n",
    "\n",
    "ridge_grid_r2 = r2_score(y_test, ridge_grid_pred)\n",
    "lasso_grid_r2 = r2_score(y_test, lasso_grid_pred)\n",
    "\n",
    "msq_grid_performance = pd.DataFrame({\n",
    "    'ridge_grid_msq': [ridge_grid_msq],\n",
    "    'lasso_grid_msq': [lasso_grid_msq]\n",
    "})\n",
    "\n",
    "r2_grid_performance = pd.DataFrame({\n",
    "    'ridge_grid_r2': [ridge_grid_r2],\n",
    "    'lasso_grid_r2': [lasso_grid_r2]\n",
    "})\n",
    "\n",
    "\n",
    "print(msq_grid_performance)\n",
    "print(r2_grid_performance)\n",
    "print(f'Optimal Alpha for Ridge Model: {ridge_grid.best_params_}')\n",
    "print(f'Optimal Alpha for Lasso Model: {lasso_grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d5c204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning the models hyperparameters only improved the Lasso model, predictably as this model performed the worse last time. However, it now sits with the Linear Model in terms of performance with an r2 of 0.3. This is still unsatisfactory when it comes to releasing an accurate model.\n"
     ]
    }
   ],
   "source": [
    "print(f'Tuning the models hyperparameters only improved the Lasso model, predictably as this model performed the worse last time. However, it now sits with the Linear Model in terms of performance with an r2 of 0.3. This is still unsatisfactory when it comes to releasing an accurate model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06280c",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "- Feature Importance:\n",
    "    - Extract and interpret the coefficients from the best Ridge and Lasso models. Rank the features by their importance.\n",
    "- Questions:\n",
    "    - According to Ridge and Lasso, which features are the most important for predicting wine quality?\n",
    "    - Do Ridge and Lasso highlight the same features, or are there differences in feature importance between the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1017c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature  Ridge Coefficient\n",
      "10               alcohol           0.322912\n",
      "1       volatile_acidity          -0.226760\n",
      "3         residual_sugar           0.187861\n",
      "6   total_sulfur_dioxide          -0.147605\n",
      "7                density          -0.138657\n",
      "5    free_sulfur_dioxide           0.124491\n",
      "9              sulphates           0.104443\n",
      "0          fixed_acidity           0.078809\n",
      "8                     pH           0.061820\n",
      "2            citric_acid          -0.022985\n",
      "4              chlorides          -0.020987\n",
      "                 Feature  Lasso Coefficient\n",
      "10               alcohol           0.334957\n",
      "1       volatile_acidity          -0.228196\n",
      "3         residual_sugar           0.170751\n",
      "6   total_sulfur_dioxide          -0.143346\n",
      "5    free_sulfur_dioxide           0.122135\n",
      "7                density          -0.111848\n",
      "9              sulphates           0.100600\n",
      "0          fixed_acidity           0.064556\n",
      "8                     pH           0.053470\n",
      "4              chlorides          -0.021464\n",
      "2            citric_acid          -0.020895\n"
     ]
    }
   ],
   "source": [
    "best_ridge_coefficients = ridge_grid.best_estimator_.coef_\n",
    "best_lasso_coefficients = lasso_grid.best_estimator_.coef_\n",
    "\n",
    "feature_names = X_unscaled.columns\n",
    "ridge_coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Ridge Coefficient': best_ridge_coefficients\n",
    "}).sort_values(by='Ridge Coefficient', key=abs, ascending=False)\n",
    "\n",
    "lasso_coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Lasso Coefficient': best_lasso_coefficients\n",
    "}).sort_values(by='Lasso Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(ridge_coef_df)\n",
    "print(lasso_coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f3cc256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Although the coefficient values vary by an insignificant value, both the Ridge and Lasso models have the same 3 top features in order for predicting wine quality. These are alcohol, volatile acidity, and residual sugar. The biggest difference, between the two models is that the Ridge model has a more signicantly value for density when compared to the Lasso. However, the absolute value difference being only 0.02 roughly means that this isnt highly significant\n"
     ]
    }
   ],
   "source": [
    "print(f'Although the coefficient values vary by an insignificant value, both the Ridge and Lasso models have the same 3 top features in order for predicting wine quality. These are alcohol, volatile acidity, and residual sugar. The biggest difference, between the two models is that the Ridge model has a more signicantly value for density when compared to the Lasso. However, the absolute value difference being only 0.02 roughly means that this isn''t highly significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1299bed",
   "metadata": {},
   "source": [
    "#### Evaluation of Model Selection\n",
    "- Model Deployment Decision:\n",
    "    - Based on the performance of Ridge, Lasso, and Linear Regression, select the best model to deploy.\n",
    "- Questions:\n",
    "    - Which model performed the best overall? Justify your choice based on MSE, R², and the feature importance results.\n",
    "    - If you were to improve the model further, what steps would you take next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8579f82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 models performed unsatisfactory with each of them only explaining 30% of the variance. Therefore I wouldnt choose any to deploy. If I had to I would maybe choose the Linear model as it takes less computational resources yet delivers a similar performance. However, going forward I would test other models such as Decision Trees and Random Forests to see if they deliver an adequate performance that would be of value. In this case I would like an r2 of over 0.7.\n"
     ]
    }
   ],
   "source": [
    "print(f'All 3 models performed unsatisfactory with each of them only explaining 30% of the variance. Therefore I wouldn''t choose any to deploy. If I had to I would maybe choose the Linear model as it takes less computational resources yet delivers a similar performance. However, going forward I would test other models such as Decision Trees and Random Forests to see if they deliver an adequate performance that would be of value. In this case I would like an r2 of over 0.7.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
