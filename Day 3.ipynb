{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f393a69f",
   "metadata": {},
   "source": [
    "# Daily Task: Predicting Iris Flower Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb5832a",
   "metadata": {},
   "source": [
    "#### Step 1: Load the Iris Dataset\n",
    "- Load the Iris dataset from sklearn.datasets.\n",
    "- Convert the dataset into a Pandas DataFrame with feature names and target species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e0595a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   Species  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "raw_data = load_iris()\n",
    "\n",
    "df = pd.DataFrame(raw_data.data, columns=raw_data.feature_names)\n",
    "df['Species'] = raw_data.target\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885476d",
   "metadata": {},
   "source": [
    "#### Step 2: Data Exploration\n",
    "- Check for missing values in the dataset.\n",
    "- Describe the basic statistics of the dataset.\n",
    "- Check the distribution of the target variable (Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abba3e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Missing Values\n",
    "df.isnull().sum()\n",
    "\n",
    "## Basic Statistics \n",
    "df.describe\n",
    "\n",
    "## Target Distribution\n",
    "df['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab82c2",
   "metadata": {},
   "source": [
    "#### Step 3: Feature Selection and Data Splitting\n",
    "- Select the feature columns and the target column (Species).\n",
    "- Split the dataset into training and testing sets (80% train, 20% test) using train_test_split from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1305a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train shape = (120, 4)\n",
      "data_test shape = (30, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data = df.drop(columns = 'Species')\n",
    "target = df['Species']\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size = 0.2)\n",
    "\n",
    "print(f'data_train shape = {data_train.shape}')\n",
    "print(f'data_test shape = {data_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1aa7b",
   "metadata": {},
   "source": [
    "#### Step 4: Train a Logistic Regression Model\n",
    "- Create and train a Logistic Regression model using LogisticRegression from sklearn.\n",
    "- Evaluate the model's accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdbafbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression(max_iter = 1000)\n",
    "log_reg.fit(data_train, target_train)\n",
    "\n",
    "score =  log_reg.score(data_test, target_test)\n",
    "\n",
    "print(f'Model accuracy = {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2dea98",
   "metadata": {},
   "source": [
    "#### Step 5: Model Interpretation\n",
    "- Print the coefficients of the trained Logistic Regression model.\n",
    "- Interpret the features with the strongest impact on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3486196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Classification Problem with 3 classes\n",
      "\n",
      "Coefficients for class 0:\n",
      "                   Coefficient  Abs_Coefficient\n",
      "petal length (cm)    -2.335806         2.335806\n",
      "petal width (cm)     -0.990408         0.990408\n",
      "sepal width (cm)      0.839192         0.839192\n",
      "sepal length (cm)    -0.518536         0.518536\n",
      "\n",
      "Coefficients for class 1:\n",
      "                   Coefficient  Abs_Coefficient\n",
      "petal width (cm)     -0.783642         0.783642\n",
      "sepal width (cm)     -0.469044         0.469044\n",
      "sepal length (cm)     0.271644         0.271644\n",
      "petal length (cm)    -0.177481         0.177481\n",
      "\n",
      "Coefficients for class 2:\n",
      "                   Coefficient  Abs_Coefficient\n",
      "petal length (cm)     2.513287         2.513287\n",
      "petal width (cm)      1.774050         1.774050\n",
      "sepal width (cm)     -0.370148         0.370148\n",
      "sepal length (cm)     0.246892         0.246892\n",
      "\n",
      "Intercepts for each class: [ 10.05716565   3.71657699 -13.77374264]\n",
      "\n",
      "Model accuracy = 0.9333\n"
     ]
    }
   ],
   "source": [
    "co_effs = log_reg.coef_\n",
    "inter = log_reg.intercept_\n",
    "\n",
    "# Step 2: Check if it's binary or multi-class classification\n",
    "if len(log_reg.classes_) == 2:\n",
    "    # Binary Classification\n",
    "    print(\"Binary Classification Problem\")\n",
    "    \n",
    "    # Get the coefficients\n",
    "    co_effs = log_reg.coef_[0]  # Only one set of coefficients for binary classification\n",
    "    feature_names = data_train.columns\n",
    "    \n",
    "    # Create a DataFrame to interpret coefficients\n",
    "    coef_df = pd.DataFrame(co_effs.T, index=feature_names, columns=['Coefficient'])\n",
    "    \n",
    "    # Sort by the absolute value of coefficients to see the most important features\n",
    "    coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "    coef_df_sorted = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance based on Coefficients for Binary Classification:\")\n",
    "    print(coef_df_sorted)\n",
    "\n",
    "else:\n",
    "    # Multi-Class Classification\n",
    "    print(f\"Multi-Class Classification Problem with {len(log_reg.classes_)} classes\")\n",
    "\n",
    "    # Loop over classes and extract coefficients for each class\n",
    "    for i in range(len(log_reg.classes_)):\n",
    "        print(f\"\\nCoefficients for class {log_reg.classes_[i]}:\")\n",
    "        \n",
    "        # Extracting coefficients for the ith class\n",
    "        co_effs = log_reg.coef_[i]\n",
    "\n",
    "        # Create a DataFrame to interpret coefficients\n",
    "        coef_df = pd.DataFrame(co_effs.T, index=data_train.columns, columns=['Coefficient'])\n",
    "\n",
    "        # Sort by the absolute value of coefficients to see the most important features\n",
    "        coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "        coef_df_sorted = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "        print(coef_df_sorted)\n",
    "\n",
    "# Step 3: Intercept\n",
    "print(f\"\\nIntercepts for each class: {log_reg.intercept_}\")\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "score = log_reg.score(data_test, target_test)\n",
    "print(f'\\nModel accuracy = {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d4a44",
   "metadata": {},
   "source": [
    "#### Step 6: Train a Decision Tree Classifier\n",
    "- Create and train a Decision Tree Classifier.\n",
    "- Evaluate the Decision Tree model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff3f93ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(data_train, target_train)\n",
    "\n",
    "dtc_score =  dtc.score(data_test, target_test)\n",
    "\n",
    "print(f'Model accuracy = {dtc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a85a0",
   "metadata": {},
   "source": [
    "#### Bonus Task: Cross-Validation\n",
    "- Perform 5-fold Cross-Validation on both Logistic Regression and Decision Tree models. Compare the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af9d2c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Results (Accuracy): [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Decision Tree Classifier Results (Accuracy): [0.96666667 0.96666667 0.9        1.         1.        ]\n",
      "Logistic Regression - Mean Accuracy: 0.9733, Std Dev: 0.0249\n",
      "Decision Tree Classifier - Mean Accuracy: 0.9667, Std Dev: 0.0365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_reg_cross_val_results = cross_val_score(log_reg, data, target, cv=5)\n",
    "dtc_cross_val_results = cross_val_score(dtc, data, target, cv=5)\n",
    "\n",
    "print(f'Logistic Regression Cross-Validation Results (Accuracy): {log_reg_cross_val_results}')\n",
    "print(f'Decision Tree Classifier Results (Accuracy): {dtc_cross_val_results}')\n",
    "\n",
    "## Additional:\n",
    "# Mean and standard deviation for Logistic Regression\n",
    "log_reg_mean = np.mean(log_reg_cross_val_results)\n",
    "log_reg_std = np.std(log_reg_cross_val_results)\n",
    "\n",
    "# Mean and standard deviation for Decision Tree Classifier\n",
    "dtc_mean = np.mean(dtc_cross_val_results)\n",
    "dtc_std = np.std(dtc_cross_val_results)\n",
    "\n",
    "print(f'Logistic Regression - Mean Accuracy: {log_reg_mean:.4f}, Std Dev: {log_reg_std:.4f}')\n",
    "print(f'Decision Tree Classifier - Mean Accuracy: {dtc_mean:.4f}, Std Dev: {dtc_std:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978187b1",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "- Mean Accuracy: This tells you the average performance of the model across the 5 folds. A higher mean accuracy is better.\n",
    "- Standard Deviation: This tells you how much the accuracy varies across the different folds. A lower standard deviation means the model is more consistent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
